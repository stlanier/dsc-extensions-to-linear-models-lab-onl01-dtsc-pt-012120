{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline boston housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the Boston housing dataset \n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "y = pd.DataFrame(boston.target, columns=['target'])\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "X_scaled = scale(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934925"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_scaled, y)\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(linreg, X_scaled, y, scoring='r2', cv=cv))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>(RM, LSTAT)</td>\n",
       "      <td>0.783201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>(RM, TAX)</td>\n",
       "      <td>0.775268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>(RM, RAD)</td>\n",
       "      <td>0.770118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>(RM, PTRATIO)</td>\n",
       "      <td>0.763594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>(INDUS, RM)</td>\n",
       "      <td>0.756628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>(NOX, RM)</td>\n",
       "      <td>0.746111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>(RM, AGE)</td>\n",
       "      <td>0.742141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            combo        r2\n",
       "56    (RM, LSTAT)  0.783201\n",
       "53      (RM, TAX)  0.775268\n",
       "52      (RM, RAD)  0.770118\n",
       "54  (RM, PTRATIO)  0.763594\n",
       "25    (INDUS, RM)  0.756628\n",
       "42      (NOX, RM)  0.746111\n",
       "50      (RM, AGE)  0.742141"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "combinations = list(combinations(X_scaled.columns, 2))\n",
    "\n",
    "r2s = []\n",
    "xtest = X_scaled.copy()\n",
    "for combo in combinations:\n",
    "    xtest['interaction'] = xtest[combo[0]]*xtest[combo[1]]\n",
    "    r2s.append(np.mean(cross_val_score(linreg, xtest, y, scoring='r2', cv=cv)))\n",
    "    \n",
    "results = pd.DataFrame([combinations, r2s]).T\n",
    "results.columns = ['combo', 'r2']\n",
    "my_combos = results.sort_values(by='r2', ascending=False)[:7]\n",
    "my_combos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>-0.444930</td>\n",
       "      <td>-0.275757</td>\n",
       "      <td>-0.406574</td>\n",
       "      <td>-0.603547</td>\n",
       "      <td>-0.532772</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.095668</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>-0.168607</td>\n",
       "      <td>-0.058883</td>\n",
       "      <td>-0.115279</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>-1.550451</td>\n",
       "      <td>-1.266461</td>\n",
       "      <td>-1.113245</td>\n",
       "      <td>-0.388783</td>\n",
       "      <td>-0.761138</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>-1.383713</td>\n",
       "      <td>-1.124148</td>\n",
       "      <td>-0.765197</td>\n",
       "      <td>0.114875</td>\n",
       "      <td>-1.328183</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>-1.261136</td>\n",
       "      <td>-1.358947</td>\n",
       "      <td>-0.925023</td>\n",
       "      <td>0.138869</td>\n",
       "      <td>-1.605599</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562 -0.444930   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439 -0.095668   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727 -1.550451   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517 -1.383713   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501 -1.261136   \n",
       "\n",
       "     RM_TAX    RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0 -0.275757 -0.406574   -0.603547 -0.532772 -0.059659 -0.049646  \n",
       "1 -0.191813 -0.168607   -0.058883 -0.115279 -0.143814  0.071331  \n",
       "2 -1.266461 -1.113245   -0.388783 -0.761138 -0.949544 -0.340960  \n",
       "3 -1.124148 -0.765197    0.114875 -1.328183 -0.848901 -0.823092  \n",
       "4 -1.358947 -0.925023    0.138869 -1.605599 -1.026210 -0.628023  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter = X_scaled.copy()\n",
    "for combo in my_combos['combo']:\n",
    "    df_inter[combo[0]+'_'+combo[1]] = df_inter[combo[0]]*df_inter[combo[1]]\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polynomials = []\n",
    "for col in X_scaled.columns:\n",
    "    for deg in [2, 3, 4]:\n",
    "        data = X_scaled.copy()\n",
    "        poly = PolynomialFeatures(deg, include_bias=False)\n",
    "        transformed_col = poly.fit_transform(data[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1), pd.DataFrame(transformed_col)], axis=1)\n",
    "        polynomials.append((col, deg, np.mean(cross_val_score(linreg, data, y, scoring='r2', cv=cv))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature\n",
       "AGE        0.722235\n",
       "B          0.719665\n",
       "CHAS       0.717678\n",
       "CRIM       0.717100\n",
       "DIS        0.736636\n",
       "INDUS      0.723299\n",
       "LSTAT      0.781953\n",
       "NOX        0.720511\n",
       "PTRATIO    0.720914\n",
       "RAD        0.719531\n",
       "RM         0.800391\n",
       "TAX        0.724010\n",
       "ZN         0.723209\n",
       "Name: r2, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = pd.DataFrame(polynomials)\n",
    "results2.columns = ['feature', 'degree', 'r2']\n",
    "results2.groupby('feature')['r2'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['RM', 'LSTAT']:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    x_trans = poly.fit_transform(df_inter[[col]])\n",
    "    colnames= [col, col + '_' + '2',  col + '_' + '3', col + '_' + '4']\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1), pd.DataFrame(x_trans, columns=colnames)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>...</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM</th>\n",
       "      <th>RM_2</th>\n",
       "      <th>RM_3</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>LSTAT_2</th>\n",
       "      <th>LSTAT_3</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059659</td>\n",
       "      <td>-0.049646</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>0.171124</td>\n",
       "      <td>0.070789</td>\n",
       "      <td>0.029284</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>1.156834</td>\n",
       "      <td>-1.244247</td>\n",
       "      <td>1.338266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143814</td>\n",
       "      <td>0.071331</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.037743</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>0.242497</td>\n",
       "      <td>-0.119415</td>\n",
       "      <td>0.058805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.949544</td>\n",
       "      <td>-0.340960</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>1.645354</td>\n",
       "      <td>2.110519</td>\n",
       "      <td>2.707191</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>1.461022</td>\n",
       "      <td>-1.765977</td>\n",
       "      <td>2.134585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.848901</td>\n",
       "      <td>-0.823092</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>1.032871</td>\n",
       "      <td>1.049709</td>\n",
       "      <td>1.066822</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>1.853728</td>\n",
       "      <td>-2.523882</td>\n",
       "      <td>3.436308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.026210</td>\n",
       "      <td>-0.628023</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>1.509401</td>\n",
       "      <td>1.854414</td>\n",
       "      <td>2.278290</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>1.053705</td>\n",
       "      <td>-1.081630</td>\n",
       "      <td>1.110295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX       AGE       DIS  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217 -0.120013  0.140214   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.367166  0.557160   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262 -0.265812  0.557160   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284 -0.809889  1.077737   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284 -0.511180  1.077737   \n",
       "\n",
       "        RAD       TAX   PTRATIO  ...    NOX_RM    RM_AGE        RM      RM_2  \\\n",
       "0 -0.982843 -0.666608 -1.459000  ... -0.059659 -0.049646  0.413672  0.171124   \n",
       "1 -0.867883 -0.987329 -0.303094  ... -0.143814  0.071331  0.194274  0.037743   \n",
       "2 -0.867883 -0.987329 -0.303094  ... -0.949544 -0.340960  1.282714  1.645354   \n",
       "3 -0.752922 -1.106115  0.113032  ... -0.848901 -0.823092  1.016303  1.032871   \n",
       "4 -0.752922 -1.106115  0.113032  ... -1.026210 -0.628023  1.228577  1.509401   \n",
       "\n",
       "       RM_3      RM_4     LSTAT   LSTAT_2   LSTAT_3   LSTAT_4  \n",
       "0  0.070789  0.029284 -1.075562  1.156834 -1.244247  1.338266  \n",
       "1  0.007332  0.001425 -0.492439  0.242497 -0.119415  0.058805  \n",
       "2  2.110519  2.707191 -1.208727  1.461022 -1.765977  2.134585  \n",
       "3  1.049709  1.066822 -1.361517  1.853728 -2.523882  3.436308  \n",
       "4  1.854414  2.278290 -1.026501  1.053705 -1.081630  1.110295  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061549447223175"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(linreg, df_inter, y, scoring='r2', cv=cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3hUZfbA8e9JCAm9ht6LlEAoAaUrgi6LLrIKK7oKWBYLWFdRdNlVf+vaV8UKa8MGurootlURAenSpAgIYoCs9BJ6QpLz++O9k0ySCRlCJpNyPs9zn9y5973vPXNncs/c9r6iqhhjjDEAEeEOwBhjTPFhScEYY0wmSwrGGGMyWVIwxhiTyZKCMcaYTJYUjDHGZLKkUAKISF0RmScih0XkqXDHk5OI9BWRjcUgjiYickREIguxzpdFZGJh1edXr4jI6yJyQESWFnb9hU1EEkVkYBDlmomIiki5Qlx3odfp1Vvo35fSwJJCmAT7T+YZA+wFqqrqn0MYVlC8f9BWvteq+p2qtglnTF4c21S1sqqmA4jIHBG5/gzrvFFV/69wIsymD3AB0EhVzw5B/SaHnP9zOb8vxrGkUDI0BX7UAjxpWNi/roqrULzPEP+CbAokqurR012wrHymJkxU1YYwDEAiMNAbHw3MB54EDgC/AL/15r0BnARSgSPAQCAaeAb41RueAaK98ucBScA9wE7gLb9p44HdwA5gKDAY+AnYD9znF9vZwCLgoFf2eaC8N28eoMBRL57LffX7Ld8OmOMtvw4Y4jfvDeAF4DPgMLAEaHmK7VQBeArYCiR726kC0MyL4zpgmxeXb1o54GEgHTjhxfm8V19b4GvvPW8E/pAjtpeAz733N9Cb9ne/Mn8CNnvLzwQa+M1T4EZgk/c5vgBIgPd0nRdXuhfbg0HWPdar+5cAdfre+zXAdm/9NwLdgdXeZ/G8X/kI4C/edt0NvAlU85t/tTdvH3A/2b+vEcC9wM/e/PeBmjniKJfH53kP8D/vs98IDDjdOoFqwKu47+b/gL8DkTk+o/XeOn4EuuL+DzKA4942Hx+g3gbedt/vfQ5/8qvzAS+mN7161wHdwr0fCcm+KdwBlNWB3EnhpPdljgRuwu3sxZv/Btl3TA8Bi4E6QCywEPg/b955QBrwGC55VPCb9lcgylvPHuBdoAoQh9tJtfDqSAB64Hauzbx/sNv91q9AK7/X5+ElBa/+zcB9QHngfO+fqI3fe9mPSzzlgHeA6afYTi/gEkxDb9v08t6X7x/6TaAS2ROF7598DnC9X12VcDvMa7x1d8Wdlovziy0Z6I3bScX4b3vvvez1losGngPm5dgunwLVgSbeNh6Ux/saDcz3ex1M3V8DNYEKAerzvfeXvbgv9D7Tj3Dfk4a4nf+5Xvlrvc+pBVAZ+A/wljevPW7H2c+L5Z+474/v+3o77vvXyJs/GZiWI45cSQFo423/Bn5lW55und57mux9nnWApcAN3rzhuETRHRCgFdA05/9cHvXOBV70tl9n7/PzJa0HvO05GPc9fARYHO79SEj2TeEOoKwO5E4Km/3mVfS+rPW812+QPSn8DAz2e/0b3KkIcDvoVCDGb/55uF9Ikd7rKl795/iVWQ4MzSPW24EZfq9PlRT64o5QIvzmTwMe8Hsvr/jNGwxsyGO9EV7cnQLM8/1DtwgwLa+kcDnwXY56JgN/84vtzRzzM7c97tfp437zKuOSeTO/7dLHb/77wL15vLfRZE8KwdR9/im+T7733tBv2j7gcr/XH+Ild+Ab4Ga/eW289ZXD/XiY7jevkved8n1f1+PtLL3X9f2WzfYZ5IixFS4xDQSicswLqk6gLpCCX2IErgC+9ca/BG7L738u5/cFaIw7cqviN/8R4A1v/AFglt+89sDxwtofFKfBrikUHzt9I6p6zButnEfZBrhDe5+t3jSfPap6Iscy+zTrgtpx7+8uv/nHfesTkbNE5FMR2Skih4B/ALWDfB8NgO2qmpEjvoZ+r3f6jR/zW+993t0gR0TkZW+dMbgkmJftQcYF7jz+OSJy0DcAfwTqBVlftu2uqkdwO95831sQgqk7mPea8zMN+BnnXJ837tvpNvBfl7rrHvv8yjYFZvhtw/W4HWrdUwWmqptxPzAeAHaLyHQR8X1vg62zKe5odIdf2cm4IwZwO/dTfV/y0gDYr6qH/abl972NKY3XdywplEy/4v45fJp403z0DOt/CdgAtFbVqrhTQXIasTUWEf/vVhPcIf0pqeo/1N0NUllVb8SdTjkBtDzVYqcxbzswV1Wr+w2VVfWmIOvLtt1FpBJQiyDeWxCCqftMP9c814f7jNJwSWQHbufqi6WiF4vPdtw1L//tGKOqwXzG76pqH2/dijvNeTp1bscdKdT2K1dVVeP85uf1fcnvs60pIlX8pgX1vS1tLCmUTNOAv4hIrIjUxh3uv12I9VcBDgFHRKQt7hqHv124c9GBLMFdpB0vIlEich7wO2D66QbhHW28BvxTRBqISKSI9BSR6CCryBnnp8BZInK1F1uUiHQXkXZB1vcucI2IdPZi+AewRFUTg1w+XHUHMg24Q0Sai0hlb33vqWoa8AFwsYj0EZHyuGtY/vuKl4GHRaQpgPc9vCS/FYpIGxE533t/J3BHLr6j16DqVNUdwFfAUyJSVUQiRKSliJzrFXkFuEtEErxnQVr56uQU31tV3Y67NveIiMSISDzuhoB38ntfpY0lhZLp78Ay3F0la4AV3rTCchdwJe4C8b+A93LMfwCY6h2+/8F/hqqmAkOA3+J+6b8IjFTVDWcQyxrge9wF6scI/nv7LDDMe0Bskndq4EJgBO6X4U6yLsjnS1W/ASbizs3vwP0iHRH8WwlP3Xl4DXdHzjzc3W4ngFu8WNbh7nR614vlAO7uNZ9ncXfpfCUih3EXiM8JYp3RwKO478VO3Cmf+wpQ50jcTQw/erF9gLsGgar+G3fn2bu47+9HuIvz4K4R/MX73t4VoN4rcNcZfgVm4K41fR3E+ypVfHe3GGOMMXakYIwxJoslBWOMMZksKRhjjMlkScEYY0ymEv3gRe3atbVZs2bhDqPEW77c/U1ICG8cpdnyX91GTmhgG9mE3/Lly/eqamygeSX67qNu3brpsmXLwh1GiSfeY2kl+KtQ7MmDbiPr32wjm/ATkeWq2i3QPDt9ZIwxJpMlBWOMMZksKRhjjMlUoi80G2OKn5MnT5KUlMSJEzkb6jVFLSYmhkaNGhEVFRX0MpYUjDGFKikpiSpVqtCsWTNEgm1c1xQ2VWXfvn0kJSXRvHnzoJez00fGmEJ14sQJatWqZQkhzESEWrVqnfYRmyUFY0yhs4RQPBTkc7CkYIwxJlNIk4KIJIrIGhFZJSLLvGk1ReRrEdnk/a3hTRcRmSQim0VktYh0DVVctzy+gKqt1jD8rnmhWoUxJsxmzJiBiLBhg+vKIzExkQ4dOmTOX7p0Kf369aNNmza0bduW66+/nmPHjuVVXZlRFEcK/VW1s9/Tc/cC36hqa1zn4fd6038LtPaGMbguIUNi/8E0Dv/ckVUrIkO1CmNMmE2bNo0+ffowfXruTv927drF8OHDeeyxx9i4cSPr169n0KBBHD58OEBNZUs4Th9dAkz1xqcCQ/2mv6nOYqC6iNQPRQDdO7m+y3cm1ghF9caYMDty5AgLFizg1VdfDZgUXnjhBUaNGkXPnj0Bd+592LBh1K1bt6hDLXZCfUuq4rrXU2Cyqk4B6nr9rKKqO0Skjle2Ia7TbZ8kb9oO/wpFZAzuSIImTZoUKKj+3V2uOfprY1Sz2v4xxhQ+X7tPgUy+eDJjEsYAMGX5FG749IY8y55Ou1EfffQRgwYN4qyzzqJmzZqsWLGCmjVrZs5fu3Yto0aNCrq+siTURwq9VbUr7tTQWBHpd4qygb45ub4FqjpFVbuparfY2ICN/OUrvnl9qLgXTanCjz8fLFAdxpjia9q0aYwY4bq4HjFiBNOmTQtzRCVHSI8UVPVX7+9uEZkBnA3sEpH63lFCfWC3VzwJaOy3eCNcB9qFTkSoVH87R3+uzbfLdhLXqnooVmOMIfhf+GMSxmQeNZyJffv2MXv2bNauXYuIkJ6ejohw8803Z5aJi4tj+fLlXHLJJWe8vtImZEcKIlJJRKr4xoELgbXATMB33DYK+NgbnwmM9O5C6gEk+04zhUKdZvsBWPrDoVCtwhgTBh988AEjR45k69atJCYmsn37dpo3b05SUlJmmXHjxjF16lSWLFmSOe3tt99m586d4Qi5WAnlkUJdYIb38EQ54F1V/a+IfA+8LyLXAduA4V75z4HBwGbgGHBNCGPj4sGRfFd5Lr27FewUlDGmeJo2bRr33ntvtmmXXXYZ//jHPzJf161bl+nTp3PXXXexe/duIiIi6NevH5deemlRh1vsWCc7xjrZKQJlqZOd9evX065du3CHYTyBPg/rZMcYY0xQymxSUFXe+WodNz+ykEOHM8IdjjHGFAtltulsEWHUaCV9Ry8Gnb2LIQPsoRVjjCmzRwoANRrvAmD+8n1hjsQYY4qHMp0UGrc4AsCqtSlhjsQYY4qHMp0UfBfkf95UZs+iGWNMNmU6KXSL9zWMVzOfksaY0qBZs2bs3bv3jMucyt13301cXBx33313gesAuO2222jYsCEZGVk3wrzxxhuMGzcu8/Wbb75Jhw4diIuLo3379jz55JNntE4owxeaAc5LaACSzrHddUlJgejocEdkjCnpJk+ezJ49e4gOcoeSlpZGuXLZd8UZGRnMmDGDxo0bM2/ePM4777xcy33xxRc888wzfPXVVzRo0IATJ07w1ltvnXH8ZfpIoX39FlD9F4hIY0viyXCHY4wpJEOHDiUhIYG4uDimTJmSa35iYiJt27Zl1KhRxMfHM2zYsGwd7Dz33HN07dqVjh07ZnbSs3TpUnr16kWXLl3o1asXGzduzFXvkCFDOHr0KOeccw7vvfceW7duZcCAAcTHxzNgwAC2bdsGwOjRo7nzzjvp378/99xzT656vv32Wzp06MBNN92UZ2N+jzzyCE8++SQNGjQAICYmhj/96U+nv7FyKNNHCtHlolm6KJpOLaIoH2Ud7hhT2E7VbPaZyO/J8Ndee42aNWty/PhxunfvzmWXXUatWrWyldm4cSOvvvoqvXv35tprr+XFF1/krrvuAqB27dqsWLGCF198kSeffJJXXnmFtm3bMm/ePMqVK8esWbO47777+PDDD7PVOXPmTCpXrsyqVasA+N3vfsfIkSMZNWoUr732GrfeeisfffQRAD/99BOzZs0iMjL3vmfatGlcccUVXHLJJdx3332cPHmSqKiobGXWrl1LQkLC6W24IJTpIwWA7m0aW0IwppSZNGkSnTp1okePHmzfvp1NmzblKtO4cWN69+4NwFVXXcX8+fMz5/naQEpISCAxMRGA5ORkhg8fTocOHbjjjjtYt25dvnEsWrSIK6+8EoCrr7462zqGDx8eMCGkpqby+eefM3ToUKpWrco555zDV199FfybP0Nl+kjBGBNa4Wjrac6cOcyaNYtFixZRsWJFzjvvPE6cOJGrnOToXcv/te96QGRkJGlpaQBMnDiR/v37M2PGDBITEwOe58+P/zoqVaoUsMx///tfkpOT6dixIwDHjh2jYsWKXHTRRdnK+Zr/Pv/88087jlMp80cKU2cvoHKLtTTutDncoRhjCkFycjI1atSgYsWKbNiwgcWLFwcst23bNhYtWgRk9eecX70NGzYE3F1AwejVq1dmd6DvvPNOvuvwxfLKK6+QmJhIYmIiv/zyC1999VW2ax4AEyZMYPz48ZnNfaekpDBp0qSg4jqVMp8UKldL5egvHfh1Q0MyrAkkY0q8QYMGkZaWRnx8PBMnTqRHjx4By7Vr146pU6cSHx/P/v37uemmm05Z7/jx45kwYQK9e/cmPT09qFgmTZrE66+/Tnx8PG+99RbPPvvsKcsfO3aML7/8MttRQaVKlejTpw+ffPJJtrKDBw9m7NixDBw4kLi4OBISEjKPas5EmW86e1vyNpo2jIajddm6FQrY7XOJZk1nh541nV28JCYmcvHFF7N27dpwhxJy1nT2aWpUtRES624tW/bD0TBHY4wx4VXmk0KERFCjkTsnN3+FNYxnTFnQrFmzMnGUUBAhTwoiEikiK0XkU+/1GyLyi4is8obO3nQRkUkisllEVotI11DH5tO4lTtC+MEaxjPGlHFFcaRwG7A+x7S7VbWzN6zypv0WaO0NY4CXiiA2ANq1dX83/xR16oLGGFPKhTQpiEgj4CLglSCKXwK8qc5ioLqI1A9lfD6X9W9N19/P5Y/XHC6K1RljTLEV6ofXngHGA1VyTH9YRP4KfAPcq6opQENgu1+ZJG/aDv8FRWQM7kiCJoV0q9Cws/sw7D+FUpUxxpRoITtSEJGLgd2qujzHrAlAW6A7UBPwtQYVqJGUXPfvqeoUVe2mqt1iY2MLM2RjTCkRGRlJ586d6dSpE127dmXhwoWAuxW1Q4cOmeWWLl1Kv379aNOmDW3btuX666/P9ZBYWRPKI4XewBARGQzEAFVF5G1VvcqbnyIirwN3ea+TgMZ+yzcCfg1hfNl8vHAdn88+yB/O7ciAvlWLarXGmBCoUKFCZqN0X375JRMmTGDu3LnZyuzatYvhw4czffp0evbsiary4YcfcvjwYSpWrBiOsIuFkB0pqOoEVW2kqs2AEcBsVb3Kd51AXCMgQwHffWEzgZHeXUg9gGRV3RGo7lC45Yn5TJnYmylvJhfVKo0xReDQoUPUqFEj1/QXXniBUaNG0bNnT8C1SzRs2DDq1q1b1CEWK+FoEO8dEYnFnS5aBdzoTf8cGAxsBo4B1xRlUK3anGQ7sH6DtXVhTGGSU7SePXkyjBnjxqdMgRtuyLvs6Txxf/z4cTp37syJEyfYsWMHs2fPzlVm7dq1jBo1KvhKy4giSQqqOgeY440HbNJPXXsbY4sinkDi48rzLbDt58AtFxpjSg7/00eLFi1i5MiR9rBakMr8E80+PTrWhoiTJO+syZEj4Y7GmNJDNe/Bd5QAbvxUZQuqZ8+e7N27lz179mSb7mt62mRnScETV7811FsJGoHXmq4xphTYsGED6enpuXpeGzduHFOnTmXJkiWZ095+++3MpqjLKutkx9OqZito+iL8ejaz56RxwQW2aYwpqXzXFABUlalTp+bq5axu3bpMnz6du+66i927dxMREUG/fv0ye10rq2zP56kQVYHG8b+w/fvj/LrvGFAr32WMMcVTXv0d5GwIr2fPnnz33XdFFVaJYEnBz7yH76PuM+WpEFMh3KEYY0xYWFLw06xWg3CHYIwxYWUXmgM4fPwEv+6w5xWMMWWPJYUcznvgAapWT2P4ldYLmzGm7LGkkEONRrshtTLLl8RQCH1gG2NMiWJJIYcLOnWAmj+RcjyKlSvDHY0xxhQtSwo59G3SF5rOA2DevDAHY4wpVM2aNWPv3r1nXOZU7r77buLi4rj77rsLtPycOXOoVq0anTt3Jj4+noEDB7J7924A3njjDcaNG5dZ9s0336RDhw7ExcXRvn17nnzyyQLH7WNJIYe4OnFUbLUMgC+/KdvtqhtjTt/kyZNZsWIFTzzxRFDl0wKcp+7bty+rVq1i9erVdO/enRdeeCFXmS+++IJnnnmGr776inXr1rFixQqqVat2xvFbUsghQiI4p3cKAAsXRJJhNyEZU+IMHTqUhIQE4uLimDJlSq75iYmJtG3bllGjRhEfH8+wYcOyda7z3HPP0bVrVzp27MiGDRsA1yFPr1696NKlC7169WLjxo256h0yZAhHjx7lnHPO4b333mPr1q0MGDCA+Ph4BgwYwLZt2wAYPXo0d955J/379+eee+7JVY+PqnL48OGATX8/8sgjPPnkkzRo4G6lj4mJ4U9/+tPpbagALCkEcGFCG6i2laOHolm3LtzRGFNyiYRmyM9rr73G8uXLWbZsGZMmTWLfvn25ymzcuJExY8awevVqqlatyosvvpg5r3bt2qxYsYKbbrop85RM27ZtmTdvHitXruShhx7ivvvuy1XnzJkzM1tovfzyyxk3bhwjR45k9erV/PGPf+TWW2/NLPvTTz8xa9YsnnrqqVz1fPfdd3Tu3JkmTZowa9Ysrr322lxl1q5dS0JCQv4b4zRZUgjg0naXMv7xjXy96Ff8eu4zxpQQkyZNolOnTvTo0YPt27ezadOmXGUaN25M7969AbjqqquYP39+5jxf+0cJCQkkJiYCkJyczPDhw+nQoQN33HEH64L4xbho0SKuvPJKAK6++ups6xg+fHiu9ph8fKePtm/fzjXXXMP48eODe+OFwJJCAGfVOovHxlzIwB4NgvpVYowJ7FRNYZ/JcCpz5sxh1qxZLFq0iB9++IEuXbpw4sSJXOUkxz+3/+vo6GjA9fXsO+c/ceJE+vfvz9q1a/nkk08C1pkf/3VUqhRc3y1DhgxhXoC7XkLV9HfIk4KIRIrIShH51HvdXESWiMgmEXlPRMp706O915u9+c1CHZsxpvRJTk6mRo0aVKxYkQ0bNrB48eKA5bZt28Yir538adOm0adPn3zrbdiwIeDuAgpGr169mD59OgDvvPNOvusIZP78+bRs2TLX9AkTJjB+/PjMpr5TUlKYNGnSadefU1EcKdwGrPd7/RjwtKq2Bg4A13nTrwMOqGor4GmvXNj8sPMHeoyaSdO4XQQ48jTGFFODBg0iLS2N+Ph4Jk6cSI8ePQKWa9euHVOnTiU+Pp79+/dz0003nbLe8ePHM2HCBHr37p1nK6w5TZo0iddff534+Hjeeustnn322aCW811T6NSpE2+99VbA6w6DBw9m7NixDBw4kLi4OBISEgLeyXTaVDVkA9AI+AY4H/gU1y/zXqCcN78n8KU3/iXQ0xsv55WTU9WfkJCgofL5T58r7f6toPrKKyFbTbHgOyg3ocMDKA+UjY38448/hjuEfP3yyy8aFxcX7jCKRKDPA1imeexXQ32k8AwwHvDd2FkLOKiqvnSWBDT0xhsC2wG8+ckE6NRARMaIyDIRWZaze73C1LNxT2jq2ln/do61d2GMKRtClhRE5GJgt6r6XwkJdNlWg5iXNUF1iqp2U9VusbGxhRBpYNVjqnNWV3eu7htLCsaUKjk72zFZQnmk0BsYIiKJwHTcKaRngOoi4uvHoRHwqzeeBDQG8OZXA/aHML58DehRB2IOsDMpBu+ZE2NMEDS/W4RMkSjI5xCypKCqE1S1kao2A0YAs1X1j8C3wDCv2CjgY298pvcab/5sDfM369zmfaCJu6/Y2kEyJjgxMTHs27fPEkOYqSr79u0jJibmtJYLR89r9wDTReTvwErgVW/6q8BbIrIZd4QwIgyxZdOnSR9o+gz89Dvmzs3gqqvssQ5j8tOoUSOSkpII5TU/E5yYmBgaNWp0WssUSVJQ1TnAHG98C3B2gDIngOFFEU+wGlZtSP+BJ9kfvYBBv+sCVAx3SMYUe1FRUTRv3jzcYZgCsj6a8zF7/DPu/iljjCkD7HyIMcaYTJYU8qGqLNiwkev/bx7vvmsXzowxpZudPgrC4Gfu5tDkmSzskMKVV0aHOxxjjAkZO1LIh4jQr1cMRKawYV15DhwId0TGGBM6lhSCcG6rs6HhElSFBQvCHY0xxoSOJYUg9G3SF5q6p9fsITZjTGlmSSEIXep3oXyLJQDMnnMyzNEYY0zoWFIIQvnI8pzdIx0kjVUrIzlyJNwRGWNMaFhSCFL/Nt2IaLKUZnG72LUr3NEYY0xo2C2pQbq7193cvymG6KiocIdijDEhY0khSFWiq4Q7BGOMCTk7fXSajqemsvD7o6SkhDsSY4wpfJYUTsPzS5+ncuvl9D67Et9/H+5ojDGm8FlSOA31K9cno67rXdSeVzDGlEaWFE5D7ya9Mx9imzs3I8zRGGNM4bOkcBrqVa5Hs05JAMxfoKSlhTkgY4wpZCFLCiISIyJLReQHEVknIg96098QkV9EZJU3dPami4hMEpHNIrJaRLqGKrYz0b9jW6j5E8eORrJqVbijMcaYwhXKI4UU4HxV7QR0BgaJSA9v3t2q2tkbfLvW3wKtvWEM8FIIYysw12+ztYNkjCmdQpYU1PE1CBHlDafqpeYS4E1vucVAdRGpH6r4Csq/cbwlS6zTHWNM6RLSawoiEikiq4DdwNequsSb9bB3iuhpEfH1WtMQ2O63eJI3LWedY0RkmYgs27NnTyjDD6hVzVY8d/sgZsxO5J13inz1xhgTUiFNCqqarqqdgUbA2SLSAZgAtAW6AzWBe7ziEqiKAHVOUdVuqtotNjY2RJHnTUQYd+6VDO3fjHLlAoVsjDElV1BJQUQuFZFNIpIsIodE5LCIHAp2Jap6EJgDDFLVHd4pohTgdeBsr1gS0NhvsUbAr8GuI1zUziAZY0qRYI8UHgeGqGo1Va2qqlVUteqpFhCRWBGp7o1XAAYCG3zXCUREgKHAWm+RmcBI7y6kHkCyqu4owHsKuUMphxjx7FPUbvsjo0eHOxpjjCk8wTaIt0tV159m3fWBqSISiUs+76vqpyIyW0RicaeLVgE3euU/BwYDm4FjwDWnub4iUzGqIp8kvsuxjX/mvwfTUY1E7EySMaYUCDYpLBOR94CPcLeaAqCq/8lrAVVdDXQJMP38PMorMDbIeMKqXEQ5enWpxayKu9m9qw6bN0Pr1uGOyhhjzlywp4+q4n69Xwj8zhsuDlVQJUHfpva8gjGm9AnqSEFVi+2pnHBxzyvMgPXDmDcPrrsu3BEZY8yZC/buo0YiMkNEdovILhH5UEQahTq44uycRucQ2XwhYI3jGWNKj2BPH72OuzuoAe6Bsk+8aWVWxaiKJHQuD9EH2bo1gm3bwh2RMcacuWAvNMeqqn8SeENEbg9FQCXJlfGXEz1qFr/pcA7VqjXOfwFjjCnmgk0Ke0XkKmCa9/oKYF9oQio5butxG7f1yL+cMcaUFMGeProW+AOwE9gBDPOmGWOMKUWCvftoGzAkxLGUSIkHE3nqtZ/ZvzaBpx+tTp064Y7IGGMK7pRJQUTGq+rjIvIcgRunuzVkkZUQD897mFeevxx+qc6lF8Fll4U7ImOMKZgtMzYAACAASURBVLj8Th/5mrZYBiwPMJR5fZv2tYfYjDGlximPFFT1E6/tog6qencRxVSiuIfYXgNg3jwlcAvgxhhTMuR7oVlV04GEIoilRGpWvRn1222HiFR++AEOHgx3RMYYU3DB3n20UkRmisjVXt8Kl4rIpSGNrIQQEfq17A4Nl6IqLFgQ7oiMMabggk0KNXHPJZyPNYiXS58mWY3jzZ0b5mCMMeYMWIN4haBvk75EtbyPKjt/pkmTluEOxxhjCiyopCAiZwEvAXVVtYOIxON6Yvt7SKMrITrW7cjhV/5DdLnocIdijDFnJNjTR/8CJgAnIbMDnRGnWkBEYkRkqYj8ICLrRORBb3pzEVni9fn8noiU96ZHe683e/ObFfRNFbUIibCEYIwpFYJNChVVdWmOaWn5LJMCnK+qnYDOwCCv7+XHgKdVtTVwAPD1RHAdcEBVWwFPe+VKlLT0dOZ8v4tly8IdiTHGFEywSWGviLTEe6pZRIbh2kDKkzpHvJdR3qC4i9UfeNOnAkO98Uu813jzB4iUnJ6P1+xaQ9VrrqD/2XW5665wR2OMMQUTbFIYC0wG2orI/4DbgRvzW0hEIkVkFbAb+Br4GTioqr6jjCRc/wx4f7cDePOTgVoB6hwjIstEZNmePXuCDD/0WtdqTVqj7wBYvFhJSclnAWOMKYaCTQqqqgOBWKCtqvYJZllVTVfVzkAj4GygXaBi3t9ARwWB2luaoqrdVLVbbGxskOGHXky5GLq3agF11pCSInz/fbgjMsaY0xdsUvgQQFWPquphb9oHpyifjaoeBOYAPYDqIuK766kR8Ks3ngQ0BvDmVwP2B7uO4sA1eWHtIBljSq5TJgURaSsilwHV/J9kFpHRQEw+y8aKSHVvvAIwENfA3re4/hgARgEfe+Mzvdd482eraq4jheLM/yE2SwrGmJIov+cU2uCeXK6Oe4rZ5zDwp3yWrQ9M9RrUiwDeV9VPReRHYLqI/B1YCbzqlX8VeEtENuOOEE55y2tx1Ltxb2gyBoAFC5S0NKFcsH3bGWNMMZBfK6kfAx+LSE9VXXQ6FXvPMnQJMH0L7vpCzukngOGns47ipkaFGnRoVYu1NTeRfqIFW7ZEctZZ4Y7KGGOCF1QnO8CVInJFzvnWyU5uLwx+gWPd0unfSYguH+5ojDHm9OR3csO/kx0ThH5N+0HTcEdhjDEFY53shFBqKpQrBxHB3uNljDFhZp3shMATC54gtsd/qVY9gx9/DHc0xhgTvGDvjVkpIjOBfwNHfRNV9T8hiaqE+2HXD+w91gCORzBvHnToEO6IjDEmONbJTgjY8wrGmJIq2KQQAdyhqtd4He7cGcKYSjz/J5vfew8WLgxzQMYYE6Rgk0K811QFAKp6gADPIBinXWw7qjfaBRV3A9C7NyxeHOagjDEmCEEfKYhIDd8LEalJ8NcjypwIiaBv0z5w8Y1UruaaS33uuTAHZYwxQQh2x/4UsFBEPsC1XPoH4OGQRVUK9G3Sl0/aj2f4sLvovvc5rr8+3BEZY0z+gkoKqvqmiCzDXWgW4FJVtZstT+GClhdww4Eb+N1Zg7jImrowxpQQQZ8C8pKAJYIgda7XmZcvfjnbtJ07Yf58GDYsj4WMMSbM7LpAEdm3D9q0gePHoVMnaN063BEZY0xu1gBDCKkqH2/4mIvfvZiKVY9z6aVw8iTcc0+4IzPGmMAsKYTYg3Mf5LNNn/H5ps95+GGoVAlmzIA5c8IdmTHG5GZJIYREhCs7XgnA+z++T4MGWUcJd94J6elhDM4YYwIIWVIQkcYi8q2IrBeRdSJymzf9ARH5n4is8obBfstMEJHNIrJRRH4TqtiK0vD2rt+gT3/6lKOpR/nzn6FRI1i5Et56K8zBGWNMDqE8UkgD/qyq7YAewFgRae/Ne1pVO3vD5wDevBFAHDAIeNFrtrtEa1q9KT0a9eDYyWN8+tOnVKwIjzzi5t1/v2te2xhjiouQJQVV3aGqK7zxw7gOexqeYpFLgOmqmqKqvwCbCdBtZ0l0edzlALy79l0ArrwSbrzRXVsob72zGWOKkSK5piAizXBtJS3xJo0TkdUi8ppf8xkNge1+iyVx6iRSYlwedznlI8szc+NMVu1cRUQEvPQSnF0qUp4xpjQJeVIQkcrAh8DtqnoIeAloCXQGduCa0AD3pHROGqC+MSKyTESW7dmzJ0RRF676Veozsd9EJg2aRPvY9rnmr18fYCFjjAmDkCYFEYnCJYR3fB3yqOouVU1X1QzgX2SdIkoCGvst3gj4NWedqjpFVbuparfY2NhQhl+o/tLvL9xyzi2Uj8w6X6QKI0ZA+/bw/fdhDM4YYzyhvPtIgFeB9ar6T7/p9f2K/R5Y643PBEaISLSINAdaA0tDFV847Tu2jwzNQASaNXPT7rjDJQljjAmnUB4p9AauBs7Pcfvp4yKyRkRWA/2BOwBUdR3wPq59pf8CY73+oUuVl5e9TItJLXh/3fsA3Hcf1KkDCxbABx+EOThjTJkXyruP5quqqGq8/+2nqnq1qnb0pg9R1R1+yzysqi1VtY2qfhGq2MKpXEQ5DqUc4v7Z95OankrVqvB//+fm3XMPnDgR3viMMWWbPdFcxEZ3Hk272u3YcmALk5dNBuDaa6FDB/jlF5g0KcwBGmPKNEsKRaxcRDkeGeCeXnto3kMcSjlEuXLwT++qy9//Drt3hzFAY0zYqUJKChw+nP1aY2IirF4NGzaEbt3WdHYYDGkzhF6Ne7Fw+0KeWvgUD/Z/kAsugKFDoXlze6DNmKKUng6HDrmdcEqKa2XA/29cHFSt6squXOluIQ9UrkYNuPnmrHrHjIFjx7Lm+5e97Tb4wx9cuX//2732L3fyZFY9KSlZ+4QrrnD9vffsCQsXhmZ7WFIIAxHh8YGP0+f1Pjy16Clu6n4T9SrX48MPIcKO3Uwpk5GRe6cI0NjvBvT5811fIzl3tCkp0KMHxMe7cqtWwXvvBS6XmgrTpkF0tCs7Zoy71TtQucsug1dfdeU2bnQ7/rzMmwd9+7rxqVPh2WcDl2vbNntSePtt954CueyyrPHUVNixI3eZqCiXDFJTs5JCq1Zw5Ai0bJl3vGfKkkKY9G7Sm0vaXMLuo7s5eOIg9SrXy5YQUlPdl0ICPdJnTIh99plr3j01FTp3hmuucdP/9z+46abAO9qUFNfI4znnuLL33gtPPhm4NeDWreGnn7JeDxoER48GjuWJJ7KSwvr18OijecedkpKVFDZvdkkkkCNHssZjYqBaNbdcdLTbAfv/rVAhq2xCgvu17j/fN16vXvZ1vPyy+//NWS46Glq0yCo3dCgkJWUvFxUV+AdiUTSiaUkhjN76/VtULl8ZybHn//hjuP12eP55uOiiMAVnyqSMDHeb9GOPZU0bNiwrKaSkwCef5L18cnLWuEhWQsi5U8y5Az333KzTJDl3uB06ZJXr1AkefjhwufLl3Q7e54UX3C/1QDt7/x19ixZw8GBw2+fqq90QjJEjgytXqZIbigtLCmFUJbpKwOk//+wuKN11F1x4ofvVYEyoHTnidngffQSRka7PjwYNXDeyPvXquR8tgXbI0dGuWXifBx+Ehx6CcuXyP+L97LPgYmzf3g3BaNcuuHImO0sKxcDGvRu5f/b93NXrLno06sG4ca7BvA0bYPJkGDcu3BGa0k4VBgyApUuhenV38XPgwNzlKlaEIUOCq9NumCiZ7LJmMTD1h6l8uP5D7pl1D6pK+fLw+ONu3t/+BgcOhDc+UzqpZt3uKAJnneUuZC5eHDghmLLBkkIxML73eGpWqMm8rfP4fNPngLv4dO65sH+/e3bBmMJy8qS7M6ZrV5g5M2v6Qw+5hOB/usiUPZYUioHqMdW5v+/9ANz7zb2kZ6QjAk8/7X7BPfccbNoU5iBNiXfwoLuTp0ULd+1g1Sp4/fWs+c2bQ61a4YvPFA+WFIqJsd3H0rRaU9buXstbq919Z126wOjR7mLfzp3hjc+UXJs3wy23uIvA48e72x/btYNXXoHp08MdnSluLCkUE9Hlovm//q5lvInfTuT4SffUy1NPuQvOvodnjDldM2a425uPHnXXCj77DNauheuuy34LpzFgSaFY+WP8H+lUtxM7j+xkwfYFgHt03v5xTTBU3SmhRx6B117Lmv6nP7mne1evhq+/hsGD7cl5kze7JbUYiZAIXh3yKtViqtGqZqts8w4ccE1sd+kS/MMzpvQ7dAhmzYLPP4cvvoBfvb4K69aFP/7RPTtQvbq7tdmYYFhSKGYSGiQEnP7FF+7Cc/368PvfQ+XKRRyYKXZeftldK0hLy5pWv747Ehg82JpIMQVjB5HFlKry4Y8fknQoCXB9OXfv7hrO8j3DUNZYd6XZtWvnmqXo0wf+8Q936uh//3MXkC+91B4eMwUTyj6aG4vItyKyXkTWicht3vSaIvK1iGzy/tbwpouITBKRzSKyWkS6hiq2kmDitxMZ9u9h/O3bvwHuHPDTT7t5Tz4J27eHMbgwGTwYzjsP/vpXd8okrwbUSrNZs9xR44ED0Ls37N0L330HEya4doHs6MCcqVAeKaQBf1bVdkAPYKyItAfuBb5R1dbAN95rgN8Crb1hDPBSCGMr9kZ3Hk25iHK88cMbrNu9DnA7geHDXSNfEyaEOcAi8Oabrg0ocA9czZsHc+e6aysXXODOlffoARMnZm9xszS77z6XHDdscG0K1agR7ohMaRPKPpp3qOoKb/wwsB5oCFwCTPWKTQWGeuOXAG+qsxioLiL1QxVfcdeqZituSLiBDM1gwjdZGeCxx9xpgXfece3UlFYvvgijRrkGAY8fd40CbtvmGmu7807o1s2dOlmyxD3xPXt21rInTpSOU02q7ojws8/c6aHLL4c1a9y8unXDG5spxVQ15APQDNgGVAUO5ph3wPv7KdDHb/o3QLcAdY0BlgHLmjRpoqXZzsM7tfI/KisPoPMS52VOv+ce12rNX/5SOOvxtYJTXOzapVq5sovphRfyLpecrPr556o33OCW8bn9dtWWLVXvvVd12TLVjIzQx5wfHkB5IO+NfOyYi/U//8malpGhWrVq1ufjG1q2VE1NLYKgTakFLNO89td5zSisAagMLAcu9V7nlRQ+C5AUEk5Vd0JCQmi2WDHywLcPKA+gPV7poRne3i05WXX27MJbR3FLCrfc4uK56KKCLd+tW/adaIsWquPHqy5dGlyCWL1aNS0t67X/eEHlTAqHDqk+9ZTq5ZertmunGhHhYi1fPvsOf8gQ1f79XaJ77TXV5ctVT5w483hM2Ra2pABEAV8Cd/pN2wjU98brAxu98cnAFYHK5TWUhaRw6MQhrfNEHeUB9KP1H4VkHcUpKWzapBoVpSrids4FkZam+u23qmPHqtarlz1BTJgQeJmUFNV331Xt3duV+/TTrHkPP+zqueAC1TvvVH39dfer/tix4GPyTwrz56s2aJA9rshI1fbtVa+4QnXfvoK9b2OCdaqkELLnFMR1J/YqsF5V/+k3ayYwCnjU+/ux3/RxIjIdOAdIVtUAPZeWLVWiq/DYwMfYeWQnF7S8INf87793nfKMGBGG4AqZquvA/ORJ1+ZTx44Fqycy0t2ldN55rj/dBQvggw/ccOGFWeU+/NB1fl6unOt7d9cuN71qVXdrp8/Gja7tqZ073RPBPhERrg+Cr75yr9PT3cXwOnXcULOmiyWnpk1dD2Vnnw033ujuGmrf3p5cN8WDuKQRgopF+gDfAWuADG/yfcAS4H2gCe46w3BV3e8lkeeBQcAx4BpVXXaqdXTr1k2XLTtlkVJt7Vq346xSxTV6VqdOwerx3cYYoq9C0Nascf0BV6nidsSFfTE1w/sW+pp4GDQIvvwya36HDjB2LFx1VfaHAzMyYOtWF5//sHEjXHyxu/gNsHt39pgjIqB2bTdtTepH8Idh6EPuSbPVq11n8YGShjGhJiLLVbVbwHmhSgpFoSwmheQTyURFRlExqiLg+nD+/HO44Qb3hGtBhDsp+He2vnIlbNkCl10W+vUuWuT6EzhyxN3q27fv6d3nn5LifvH7kvH27S6h7N7thv37cywweCz62QuFFr8xBWVJoZR4f9373PzZzdzR4w7u7+f6X1i/3h0tqMIPP2Tv5DxY4UgKqllNd0RHw6efFt26i8rJk+7hsl27oMtTv4GqSegL68IdljGnTArWzEUJElsxln3H9/HYgsfYc3QP4Jo6uPFGd4rjz38O/ymgYN15pzvKmTXLPZC2b1+4Iyp8UVGuLaLOnYFWX0GdH8MdkjH5sqRQgvRv3p9BrQZxOPUwD3/3cOb0Bx6AatXcBc8vvghffMGaMQOeecbtNB97zD2UZj1+GVM8WFIoYR4d8CiC8OL3L7LlwBbAXcz861/d/AcfDGNwQVi7Fq691o0/8YTrCcyaajCm+LCkUMJ0qteJq+Kv4mTGSSZ+OzFz+rhxcO+98PHHp1j4DBw+DPPnu536zp3ufPnp2rbNnUo5eBCGDIFbby38OI0xZ8YuNJdAiQcTafN8G1LTU1k+Zjld62dvUHbXLpg0yV2E3r0bhg51v85r1gxcX34XmmfMgJtvzt5PdFycSxC+5YYPdw3U1a4NsbFZf6tVcw35+YwY4co9/rh7HqCskAfdRta/ldz/N1N6nOpCs3WyUwI1q96Mcd3HMTtxNmkZabnmp6e7BtR8FixwLYleeaW7D79rHo2Sjxzpdvb33JNVz+9/D5984l6fdZa7r37Pnuz34x896h4Ey8u8eVl9TE+bZs07G1Oc2ZFCCXX85HGiy0UTIbnPAKrCQw+5nXj58q7Tlf/+N2t+YqJ7qtbHfyd93nnw7bdu/PBh92u+UiV49FF3tOB78Es1a7mUFPesxJ497hbMnH+vuMLdGVWW2ZGCKU7sSKEUqhBVIc95IvC3v2W9vuwy2LQJXnrJ9eHrSwiq8NxzWeXuvx969sxez733ugfjmjXLvQ6f6Gh3RGGMKfnsSKGE23pwK3+d81cGtxrM5R0uP61lFyxwXTn6HDjgzvebwmdHCqY4sYfXSrFZW2bx5g9vct/s+0hNTz2tZatVgz/8Ieu1JQRjjCWFEm5U51G0q92OLQe2MHnZ5NNatkMHeO+9EAVmjCmRLCmUcOUiyvHowEcBeGjeQxxKORTmiIwxJZklhVLgd2f9jt6Ne7P32F6eXPhkuMMxxpRglhRKARHh8QseB+CpRU+x43CZ75vIGFNAlhRKiV6NezG07VCOnzzO11u+zn8BY4wJIGRJQUReE5HdIrLWb9oDIvI/EVnlDYP95k0Qkc0islFEfhOquEqzJy94ktU3rWZkp5HhDsUYU0KF8kjhDVzXmjk9raqdveFzABFpD4wA4rxlXhQR66jwNLWs2ZIOdbJ62Xl52cuZ/S4YY0wwQpYUVHUekLNDwrxcAkxX1RRV/QXYDJwdqtjKgllbZnHTZzfR+rnWTF42mQzNyH8hY0yZF45rCuNEZLV3esnXkn5DYLtfmSRvmimgRlUb8ZuWvyE5JZkbP7uR86eez6Z9m8IdljGmmCvqpPAS0BLoDOwAnvKmB2o3M2B7ACIyRkSWiciyPXvs1Ehe2tZuyxd//IL3h71PnUp1mLt1LvEvx/PEgicCtqxqjDFQxElBVXeparqqZgD/IusUURLQ2K9oI+DXPOqYoqrdVLVbbGxsaAMu4USE4XHD+fHmHxnZaSQn0k4wftZ4Hl/weLhDM8YUU0WaFESkvt/L3wO+O5NmAiNEJFpEmgOtgaVFGVtpVqtiLaYOncoXf/yC3o17M+7sceEOyRhTTIWs6WwRmQacB9QWkSTgb8B5ItIZd2ooEbgBQFXXicj7wI9AGjBWVdNDFVtZNajVIAa1yroh7NjJY/zh338APgXglwO/0LxG8zBFZ4wpDkKWFFT1igCTXz1F+YeBh0MVj8lt0pJJfLbps8zXLSe15DetfsONCTdy0VkXUS7CutswpqyxJ5rLsNt73M79fe/PfK0o/938X4a+N5Tnlz4fxsiMMeFiPwXLsJhyMfz9/L9nHp7tvXsvU3+Yyhur3uDKjldmlrt6xtWs3LGS5jWa06tRL/o27Uv3Bt2JLhcdnsCNMSFjPa+ZzK418/oqdJvSjeU7lmebFh0ZTfeG3bm287Vc0+WakMX27OJnmbt1LpXKV6Jvk770a9qPNrXaIBLoLubiy3peM8WJ9dFszsiXV31J0qEkftzzI/O3zee7bd+xZvca5m+bz4DmAzLLrdm1hn+t+Bd9m/Slb9O+1KtcL886U9NT+Xn/z4gIURFRlI8sT1RkFIu2L+Kisy6ifGR5AOZvn8+MDTMAeHv12wDEVoylX9N+DGs/jBEdRoTwnRtT9lhSMPmqVbEWtSrWolO9TlzR0d0/cOD4ARZsX8BZtc7KLPflz1/y3NLneG7pcwC0qtmKvk36Ur9yfapGV+WePvcAsOvILlpMasGxk8cCru/9Ye8zPG44ADd3u5lh7Yax7/g+5m6dy7yt89h5ZCcfrv+QupXqZiaFLQe28MziZ+hSrwtd63elfWx7oiKjQrZNTOHxna3wHf1laAap6amoKoqiqmRoRuZ45fKViYxwTaMdTjnM8bTjucooSlREFHUr181cx5YDWwLWl6EZNKjSgBoVXAMLe47uIelQEopXzqvP11RMj0Y9MmNf/utyDqcezlbGN96oaiPax7YH3P/L/G3zA9apqlzQ8gKqx7j+cBcnLebn/T/nilFRYivG8rs2vwvp52FJwRRIjQo1uPisi7NNu7DlhRw/eZzvtn3Hwu0L2bx/M5v3bwagRY0WmUmhTqU6xFaMJUIiiIqM4mT6SU5mnORk+knqV6mfbWfev3n/zPGbu9+MqrJ5/2bmbp2brfG/hdsXZiYjcKe3OtbtSNd6XelSvwujOo2iQlSFkGyL0mbH4R1c/sHlJB1KytwZ+XZeGZrBP3/zz8xk/OqKV7ln1j0Bd3blIspx4J4DmfV2m9KN1btW59p5g0v+L1z0AgBLkpbQ67Veeca36oZVdKrXCYBb/3srb6x6I2C5cxqew+LrFwOQlpFGq+da5Vnnq0Ne5dou1wLw3rr3uOWLWwKWKxdRjpMTT2a+vubja1ize03Asv7vacPeDQyZPuSU76l6PZcUJi+ffMr3ZEnBlBjxdeOJrxsPuH/CVTtXsWDbAg6nHqZOpTqZ5USEtTevpXL5yqe9DhGhda3WtK7VOtv0hPoJPDLgEVbuXMmKHSvYvH8zy35dxrJfl1E+sjzXdbkus+w/vvsHlaIq0bV+VzrV60TV6KoFfMcly7GTx9iWvI3tydvZlrzNDYe2sfXgVipEVeCzK93tybGVYlm5cyVHUo8ErOdo6tHM8RNpJ9h3fF/AcpE5GjpOTU/lZMbJgGV9yQEgMiKS8pHlEQQRIUIiMscF99qnavmq1K5YO2CZ2EpZLR6ICM2rN89Vn2+8WnS1zLKxFWPpVLeTm+dXn4jkuk07oUECNSrUyFbGN962dtvMcjUr1OSi1hdlW6d/+WoxWevv0bAHqempAd9/yxotA26/wmQXmk2+F5pLouQTyazauYqVO1ey//h+Hur/EOBOTVR/tDqHUw9nlq1SvgoiQoZm8NSFTzEmYQzgjj6eXfIsHet0dEPdjjSr3izbTilYhXmhOTU9NfOaS1pGGvO2zuNQyiEOpRzicMphDqUcIjklmV8P/8otZ99C94bdAXhgzgM8OPfBgHVWKV+F5HuTM0/hLE5aTGzFWCIjInPtnKrHVKdS+UoAHD95nCOpRwLuQAWhSnSVzHWkpKVkTs9Z1hQtu9BsypxqMdU4t9m5nNvs3GzT0zLSeGzgY5lHFGt2r8mWIFLTUzPHF21fxPvr3uf9de9nTqsUVYkOdTrQsU5HXrr4pSJ9wE9V+eeifzLzp5nMHT0XgJPpJxnw5oA8lzm36bmZSaFZ9Wa0rNGSRlUb0bR6U5pUbUKTak3ceLUm2ZbzP29+KhWiKgR9Ws5uYS4ZLCmYMqV8ZHlu6n5T5uv0jHQOpx7O/NXqv+P6fbvfU6tiLdbsWsOa3W7YeWQnS/63hKRDSdkSQu/Xemde2KxTsQ51KmUNXet3zSy3etdqvtnyDZv2b2LLgS0cO3mM1PRUUtNTiSkXw8LrFmaWPeeVc9i0b1PmaRdfwqoUVYnEg4k0q96MmHIxDGg+gErlK1GlfBWqRlfN/Fu/Sn36Ne2XWd/ozqMZ3Xl0KDarKUUsKZgyLTIiMvOuj5xa1GhBixotsk3be2wva3atITklOXPakdQjLNy+MOfimSYNmpQ5/vXPX3PX13cFLFcxqmK218knkjlw4kC2aZESSce6HWlYxXU3IiLMGjkrz3Ubc7osKRhzGmpXrJ3tjihwv9y33LqFnw/8zO6ju3MN7WLbZZbt1bgXY7uPpVXNVrSq2Yqq0VXdMxresxr+5l87392h5fccR0GuZxhzOiwpGHOGRITmNZoH1cJsz8Y96dm4Z1D11q5Y+0xDM+a02c8OY4wxmSwpGGOMyWRJwRhjTCZLCsYYYzKFLCmIyGsisltE1vpNqykiX4vIJu9vDW+6iMgkEdksIqtFpGveNRtjjAmVUB4pvAEMyjHtXuAbVW0NfOO9Bvgt0NobxgAvhTAuY4wxeQhZUlDVecD+HJMvAaZ641OBoX7T31RnMVBdROqHKjZjjDGBFfU1hbqqugPA++trOrMhsN2vXJI3LRcRGSMiy0Rk2Z49e0IarDHGlDXF5eG1QM0kBmxOUlWnAFMARGSPiGwtwPpqA3sLsFxRCUt8p9FYpW2/ApIHMjdysY3RY/GdmeIeX9O8ZhR1UtglIvVVdYd3emi3Nz0JaOxXrhHwa36VqWpsfmUCEZFleTUbWxxYfGemuMcHxT9Gi+/MFPf4TqWoTx/NBEZ546OAj/2mj/TuQuoBJPtOMxljjCk6ITtSEJFpwHlAbRFJAv4GPAq8LyLXAduA4V7xz4HBwGbgGHBNv1rj/AAABo5JREFUqOIyxhiTt5AlBVW9Io9ZuXoEUdf929hQxRLAlCJcV0FYfGemuMcHxT9Gi+/MFPf48lSiu+M0xhhTuKyZC2OMMZksKRhjjMlUapOCiAwSkY1ee0r3Bpg/2nvOYZU3XF/E8eVqGyrH/LC2BxVEfOeJSLLf9vtrEcfXWES+FZH1IrJORG4LUCZs2zDI+MK9DWNEZKmI/ODF+GCAMtEi8p63DZeISLNiFl9Y/4+9GCJFZKWIfBpgXti2X4GpaqkbgEjgZ6AFUB74AWifo8xo4PkwxtgP6AqszWP+YOAL3IN9PYAlxSy+84BPw7j96gNdvfEqwE8BPuOwbcMg4wv3NhSgsjceBSwBeuQoczPwsjc+AnivmMUX1v9jL4Y7gXcDfZbh3H4FHUrrkcLZwGZV3aKqqcB0XPtKxYYGbhvKX1jbgwoivrBS1R2qusIbPwysJ3fTKGHbhkHGF1bedjnivYzyhpx3nvi3V/YBMEDkNJ59D318YSUijYCLgFfyKBK27VdQpTUpBNuW0mXeaYUPRKRxgPnhFHR7UGHU0zu0/0JE4sIVhHdI3gX3S9JfsdiGp4gPwrwNvVMfq3CtC3ytqnluQ1VNA5KBWsUoPgjv//EzwHggI4/5Yd1+BVFak0IwbSl9AjRT1XhgFlnZvLgIuj2oMFkBNFXVTsBzwEfhCEJEKgMfArer6qGcswMsUqTbMJ/4wr4NVTVdVTvjmpY5W0Q65CgS1m0YRHxh+z8WkYuB3aq6/FTFAkwrTv/HuZTWpJBvW0qquk9VU7yX/wISiii2YBWoPaiioqqHfIf2qvo5ECUitYsyBhGJwu1w31HV/wQoEtZtmF98xWEb+sVyEJhD7j5QMrehiJQDqhGG04p5xRfm/+PewBARScSdoj5fRN7OUaZYbL/TUVqTwvdAaxFpLiLlcRd4ZvoXyHFueQjunG9xUqzbgxKRer5zoyJyNu67tK8I1y/Aq8B6Vf1nHsXCtg2Dia8YbMNYEanujVcABgIbchTzb69sGDBbvaumxSG+cP4fq+oEVW2kqs1w+5jZqnpVjmJh234FVVyazi5UqpomIuOAL3F3Ir2mqutE5CFgmarOBG4VkSFAGi5zjy7KGCVw21BRXvwvE+b2oIKIbxhwk4ikAceBEUX8Ze/N/7d3P69VXGEYx78PQQgFN+ImXdiIrQt/tFZjQatL1ypFtITQtMVVQ2yzLJWi/0EkuhGlInZRMUVwEQxZaSW0qdhmUSgV3UnThQq1oYv27eKcTA63N7k3yYUryfOBwMyZM3POHZh5M+feeQ/0AdN5zBngc2BT0cd2nsNm+tfuc9gFXJHUQQpI30TErZrr5BJwVdJvpOvkxEvWv7Zex/W8ROdvWZzmwszMKqt1+MjMzJbBQcHMzCoOCmZmVnFQMDOzioOCmZlVHBRszcoZNkdWsH9XvcyYNXW6tUCm2aXUqbPPgCRPW2st56BgtnxDpLdo2+EyMNimtm0Vc1AwAyS9JmkiJ1abkLQpl2+RNCnpB0lnJf1Z7PYeMJbrdUu6I+l+/ttfp41+STcljSnN9fFlsblD0kWleQNu5zd4kXQyt/2TpBuSXgGIiL+Ax/lNaLOWcVAwS0ZIabbfBK4B53L5MDAcEXsp8iZJ2gw8LfLuzACHImI3cLzYv9Y7QC+wCzgmqSeXvwGcj4jtwDNSwAEYjYi9OWneL8DHxbGmgIPL/cBm9TgomCX7SBOlAFwFDhTl1/Py10X9LuCPYn0dcFHSdK6/bYF2xnMSt1lgtGjnUUTMpcP4EejOyzvyE8g0KZiU6bVngFeb+3hmzXFQsDVF0ifKUzey+A21Uf6XWaCzWP8M+B14C+ghzfjXzHHn1v8uyv5hPi/ZV8BAROwEztS02Zn7YdYyDgq2pkTE+YjYlXP0l2m07zGfrKwXuJuXJ5kfyimTmf3K/H/zkFIiP4mIf0mJ8DoW6MIhSRvydwZHgO8adHk98CSn4e6t2bYVWNKvlswacVAwSwaBDyX9TLqpn8rlnwJDkr4nDRk9B4iIF8BDSa/neheADyRNkm7WLxZo5y5peOoBcCMiphr06zRpxrZx/p/W+l3SxDJmLeMsqWaLyL/2mY2IkHQCeD8iDudtR4E9EfFFk8fqB3oiYqAF/XobGIqIvpUey6y0KudTMGuhPcBIngznGfDR3IaI+FZSu+bb3Uh6ijBrKT8pmJlZxd8pmJlZxUHBzMwqDgpmZlZxUDAzs4qDgpmZVf4DNeYV4WM7cXoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label=name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2, label='alpha for %s'%name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "    \n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare R-squared and MSE using train-test split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7168057552393374\n",
      "Test r^2: 0.7789410172622857\n",
      "Training MSE: 22.477983821877896\n",
      "Test MSE: 21.897765396049497\n"
     ]
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=1)\n",
    "\n",
    "# Code for baseline model\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', linreg_all.score(X_train, y_train))\n",
    "print('Test r^2:', linreg_all.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8318173711708374\n",
      "Test r^2: 0.8548188862719714\n",
      "Training MSE: 13.349163974493079\n",
      "Test MSE: 14.381419515196054\n"
     ]
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y, random_state=1)\n",
    "\n",
    "# Code for lasso with alpha from AIC\n",
    "lasso = Lasso(alpha=model_aic.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Test r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.8289395133356199\n",
      "Test r^2: 0.8619985551393496\n",
      "Training MSE: 13.577588255912898\n",
      "Test MSE: 13.670212476549224\n"
     ]
    }
   ],
   "source": [
    "# Code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha=model_bic.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print R2 and MSE\n",
    "print('Training r^2:', lasso.score(X_train, y_train))\n",
    "print('Test r^2:', lasso.score(X_test, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
